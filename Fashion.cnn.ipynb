{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importing important libaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense,Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "test=pd.read_csv(\"fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0      2       0       0       0       0       0       0       0       0   \n",
      "1      9       0       0       0       0       0       0       0       0   \n",
      "2      6       0       0       0       0       0       0       0       5   \n",
      "3      0       0       0       0       1       2       0       0       0   \n",
      "4      3       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0        30        43         0   \n",
      "3       0  ...         3         0         0         0         0         1   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel781  pixel782  pixel783  pixel784  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n",
      "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0      0       0       0       0       0       0       0       0       9   \n",
      "1      1       0       0       0       0       0       0       0       0   \n",
      "2      2       0       0       0       0       0       0      14      53   \n",
      "3      2       0       0       0       0       0       0       0       0   \n",
      "4      3       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
      "0       8  ...       103        87        56         0         0         0   \n",
      "1       0  ...        34         0         0         0         0         0   \n",
      "2      99  ...         0         0         0         0        63        53   \n",
      "3       0  ...       137       126       140         0       133       224   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel781  pixel782  pixel783  pixel784  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2        31         0         0         0  \n",
      "3       222        56         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 785)\n",
      "(10000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       785\n",
       "unique        1\n",
       "top       False\n",
       "freq        785\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       785\n",
       "unique        1\n",
       "top       False\n",
       "freq        785\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train[\"label\"]\n",
    "X=train.drop(labels=\"label\",axis=1)\n",
    "y_test=test[\"label\"]\n",
    "X_test=test.drop(labels=\"label\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X/255.0\n",
    "X_test=X_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape rhe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.values.reshape(-1,28,28,1)\n",
    "X_test=X_test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=to_categorical(y,num_classes=10)\n",
    "y_test=to_categorical(y_test,num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now splitting the data into training data and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_valid=train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(X_train[5][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()\n",
    "classifier.add(Convolution2D(filters=32,kernel_size=(5,5),padding=\"same\",activation=\"relu\",input_shape=(28,28,1)))\n",
    "classifier.add(Convolution2D(filters=32,kernel_size=(5,5),padding=\"same\",activation=\"relu\"))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Dropout(0.50))               \n",
    "               \n",
    "classifier.add(Convolution2D(filters=64,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "classifier.add(Convolution2D(filters=64,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Dropout(0.25))               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units=256,activation=\"relu\"))\n",
    "classifier.add(Dropout(0.25))\n",
    "classifier.add(Dense(units=10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 887,530\n",
      "Trainable params: 887,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=tf.keras.optimizers.Adam(learning_rate=0.001,\n",
    "                        beta_1=0.9,\n",
    "                        beta_2=0.999,\n",
    "                        epsilon=1e-07,\n",
    "                        amsgrad=False,\n",
    "                        name=\"Adam\"\n",
    ")\n",
    "los=tf.keras.losses.CategoricalCrossentropy(from_logits=False,\n",
    "                                            label_smoothing=0,\n",
    "                                            reduction=\"auto\",\n",
    "                                            name=\"categorical_crossentropy\"\n",
    ")\n",
    "classifier.compile(optimizer=adam,loss=los,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-e115f7487066>:15: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/10\n",
      "558/558 - 156s - loss: 0.7189 - accuracy: 0.7287 - val_loss: 0.4229 - val_accuracy: 0.8382\n",
      "Epoch 2/10\n",
      "558/558 - 157s - loss: 0.4909 - accuracy: 0.8137 - val_loss: 0.3467 - val_accuracy: 0.8659\n",
      "Epoch 3/10\n",
      "558/558 - 173s - loss: 0.4361 - accuracy: 0.8370 - val_loss: 0.3258 - val_accuracy: 0.8740\n",
      "Epoch 4/10\n",
      "558/558 - 170s - loss: 0.4048 - accuracy: 0.8481 - val_loss: 0.3161 - val_accuracy: 0.8793\n",
      "Epoch 5/10\n",
      "558/558 - 166s - loss: 0.3811 - accuracy: 0.8579 - val_loss: 0.2766 - val_accuracy: 0.8929\n",
      "Epoch 6/10\n",
      "558/558 - 158s - loss: 0.3632 - accuracy: 0.8632 - val_loss: 0.2729 - val_accuracy: 0.8972\n",
      "Epoch 7/10\n",
      "558/558 - 157s - loss: 0.3542 - accuracy: 0.8662 - val_loss: 0.2757 - val_accuracy: 0.8940\n",
      "Epoch 8/10\n",
      "558/558 - 157s - loss: 0.3423 - accuracy: 0.8712 - val_loss: 0.2495 - val_accuracy: 0.9079\n",
      "Epoch 9/10\n",
      "558/558 - 157s - loss: 0.3382 - accuracy: 0.8741 - val_loss: 0.2509 - val_accuracy: 0.9055\n",
      "Epoch 10/10\n",
      "558/558 - 157s - loss: 0.3273 - accuracy: 0.8786 - val_loss: 0.2373 - val_accuracy: 0.9100\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                                    samplewise_center=False,  # set each sample mean to 0\n",
    "                                    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                                    samplewise_std_normalization=False,  # divide each input by its std\n",
    "                                    zca_whitening=False,  # apply ZCA whitening\n",
    "                                    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                                    zoom_range = 0.1, # Randomly zoom image \n",
    "                                    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "                                    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "                                    horizontal_flip=False,  # randomly flip images\n",
    "                                    vertical_flip=False)  # randomly flip images)\n",
    "\n",
    "train_datagen.fit(X_train)\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "history = classifier.fit_generator(train_datagen.flow(X_train,y_train, batch_size=86),\n",
    "                              epochs = 10, validation_data = (X_val,y_valid),\n",
    "                              verbose = 2, steps_per_epoch=X_train.shape[0] // 86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.225907564163208\n",
      "Test accuracy: 0.9132000207901001\n"
     ]
    }
   ],
   "source": [
    "score = classifier.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.225907564163208, 0.9132000207901001]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
